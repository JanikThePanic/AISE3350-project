{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><b>Western University</b></center>\n",
    "## <center><b>Faculty of Engineering</b></center>\n",
    "## <center><b>Department of Electrical and Computer Engineering</b></center>\n",
    "\n",
    "# <center><b>AISE 3350A FW24: Cyber-Physical Systems Theory</b></center>\n",
    "# <center><b>Group 13 - Project</b></center>\n",
    "\n",
    "\n",
    "Students:\n",
    "- Jahangir (Janik) Abdullayev (251283871)\n",
    "- Richard Augustine (251275608)\n",
    "- Matthew Linders (251296414)\n",
    "- Xander Chin  (251314531)\n",
    "- Joseph Kim (251283383)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentation of the M&Ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code dependencies\n",
    "\n",
    "# For CV\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from fastsam import FastSAM, FastSAMPrompt\n",
    "import numpy as np\n",
    "\n",
    "# Also need the FastSAM model which is downloaded from google drive:\n",
    "# https://drive.google.com/file/d/1m1sjY4ihXBU1fZXdQ-Xdj-mDltW-2Rqv/view\n",
    "# Place the downloaded FastSAM-x.py file alongside this jupyter notebook file\n",
    "\n",
    "# For GUI\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "# Applies the mask to passed image\n",
    "def apply_mask(image, xy_array):\n",
    "    # Create empty mask of same size as image\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    \n",
    "    # Fill polygon defined by xy coordinates with ones\n",
    "    cv2.fillPoly(mask, [xy_array], 1)\n",
    "    \n",
    "    # Apply mask to image\n",
    "    masked_image = image.copy()\n",
    "    masked_image[mask == 0] = 0\n",
    "    \n",
    "    return masked_image\n",
    "\n",
    "# Checks how circular the passed contour is\n",
    "def check_circularity(contour):\n",
    "    # Calculate area and perimeter\n",
    "    area = cv2.contourArea(contour)\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    \n",
    "    # Circularity using isoperimetric inequality\n",
    "    circularity = 4 * np.pi * area / (perimeter * perimeter)\n",
    "    \n",
    "    # Fit an ellipse and check ratio of axes\n",
    "    if len(contour) >= 5:  # Need at least 5 points to fit ellipse\n",
    "        ellipse = cv2.fitEllipse(contour)\n",
    "        major_axis = max(ellipse[1])\n",
    "        minor_axis = min(ellipse[1])\n",
    "        axis_ratio = minor_axis / major_axis\n",
    "    else:\n",
    "        axis_ratio = 0\n",
    "    \n",
    "    # Combine metrics (weight them equally)\n",
    "    final_score = (circularity + axis_ratio) / 2\n",
    "    \n",
    "    return final_score\n",
    "\n",
    "# Returns average colour of the passed image\n",
    "def get_average_color(img):\n",
    "    pixels = np.array(img)\n",
    "    \n",
    "    # Create mask for non-black pixels (where not all RGB values are 0)\n",
    "    non_black_mask = ~np.all(pixels == 0, axis=2)\n",
    "    \n",
    "    # Only consider non-black pixels for average\n",
    "    valid_pixels = pixels[non_black_mask]\n",
    "    \n",
    "    # Return average of valid pixels, or [0,0,0] if all pixels were black\n",
    "    if len(valid_pixels) > 0:\n",
    "        avg_rgb = np.round(valid_pixels.mean(axis=0)).astype(int)\n",
    "        return avg_rgb\n",
    "    return np.array([0, 0, 0])\n",
    "\n",
    "# Predefined colors\n",
    "def classify_color(rgb):\n",
    "    color_dict = {\n",
    "        'Red': [206, 38, 38],\n",
    "        'Orange': [255, 120, 0],\n",
    "        'Yellow': [255, 255, 0],\n",
    "        'Green': [0, 204, 0],\n",
    "        'Blue': [51, 153, 255],\n",
    "        'Brown': [70, 5, 5],\n",
    "        'White': [255, 255, 255]\n",
    "    }\n",
    "    \n",
    "    distances = {\n",
    "        color: np.sqrt(sum((rgb - np.array(ref_rgb))**2))\n",
    "        for color, ref_rgb in color_dict.items()\n",
    "    }\n",
    "    \n",
    "    return min(distances.items(), key=lambda x: x[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main image processing function\n",
    "# Takes the path to the image on the machine along with the reference to the GUI output textbox\n",
    "def processImage(img_url, output_text):\n",
    "\n",
    "    # Handle the case the image path is None\n",
    "    if img_url == None:\n",
    "        print(\"No image loaded\")\n",
    "        return\n",
    "    \n",
    "    # Load and the image in the terminal\n",
    "    raw_image = cv2.cvtColor(cv2.imread(img_url), cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(raw_image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    # Load the fastSAM\n",
    "    modelSAM = FastSAM(\"FastSAM-x.pt\")\n",
    "\n",
    "    # Stores results provided the passed settings\n",
    "    everything_results = modelSAM(\n",
    "        img_url,\n",
    "        device=\"cpu\",\n",
    "        retina_masks=True,\n",
    "        imgsz=384,\n",
    "        conf=0.3,\n",
    "        iou=0.9,\n",
    "    )\n",
    "    prompt_process = FastSAMPrompt(img_url, everything_results, device=\"cpu\")\n",
    "\n",
    "    # Everything prompt\n",
    "    prompt_process.everything_prompt()\n",
    "\n",
    "    num_of_masks = len(everything_results[0])\n",
    "    print(num_of_masks)\n",
    "\n",
    "    # Display images with matplotlib\n",
    "    fig, axes = plt.subplots(nrows=int(np.ceil(num_of_masks / 6)), ncols=6, figsize=(10, 5))\n",
    "\n",
    "    # Flatten the axes array for easy iteration\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    final_dict = {\n",
    "        \"Red\": 0,\n",
    "        \"Orange\": 0,\n",
    "        \"Yellow\": 0,\n",
    "        \"Green\": 0,\n",
    "        \"Blue\": 0,\n",
    "        \"Brown\": 0,\n",
    "        \"White\": 0,\n",
    "    }\n",
    "    for index, r in enumerate(everything_results[0]):\n",
    "        maskCoords = (r.masks.xy)[0]\n",
    "        xy_array = np.array(maskCoords)\n",
    "\n",
    "        CIRCULAR_THRESHOLD = 0.75\n",
    "        \n",
    "        # Checks if the mask is circular enough\n",
    "        if(check_circularity(xy_array) > CIRCULAR_THRESHOLD):   \n",
    "            contour = xy_array.reshape((-1, 1, 2)).astype(np.int32)\n",
    "            # Create binary mask from contour\n",
    "            mask = np.zeros(raw_image.shape[:2], dtype=np.uint8)\n",
    "            cv2.fillPoly(mask, [contour], 255)\n",
    "\n",
    "            # Apply mask to image\n",
    "            masked_image = cv2.bitwise_and(raw_image, raw_image, mask=mask)\n",
    "\n",
    "            # Get bounding box just to determine region of interest\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            result_image = masked_image[y:y+h, x:x+w]\n",
    "\n",
    "            # Get average RGB and classify it as a color\n",
    "            avg_rgb = get_average_color(result_image)\n",
    "            color_category = classify_color(avg_rgb)\n",
    "            final_dict[color_category] += 1\n",
    "\n",
    "            ax = axes[index]\n",
    "            ax.axis(\"off\")\n",
    "            ax.imshow(result_image)\n",
    "\n",
    "    print(final_dict)\n",
    "\n",
    "    # Display results in the GUI output box\n",
    "    output_text.delete(\"1.0\", tk.END)  # Clear previous text\n",
    "    output_text.insert(tk.END, final_dict)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main script for GUI\n",
    "\n",
    "# Initialize the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Image and Info Display GUI\")\n",
    "root.geometry(\"400x600\")\n",
    "\n",
    "# Upload image button\n",
    "upload_button = ttk.Button(\n",
    "    root, text=\"Upload Image\", command=uploadImage\n",
    ")\n",
    "upload_button.pack(pady=10)\n",
    "\n",
    "# Upload process button\n",
    "upload_button = ttk.Button(\n",
    "    root, text=\"Process Image\", command=lambda: processImage(file_path, output_text)\n",
    ")\n",
    "upload_button.pack(pady=10)\n",
    "\n",
    "# Image display label\n",
    "image_label = tk.Label(root)\n",
    "image_label.pack(pady=10)\n",
    "\n",
    "# File path label\n",
    "file_path_label = tk.Label(root, text=\"No file selected\", wraplength=300)\n",
    "file_path_label.pack()\n",
    "\n",
    "# Text box for output information\n",
    "output_text = tk.Text(root, height=10, width=40, state=tk.NORMAL)\n",
    "output_text.pack(pady=10)\n",
    "\n",
    "# Run the main loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle uploading the image\n",
    "def uploadImage():\n",
    "    global file_path\n",
    "    file_path = filedialog.askopenfilename(\n",
    "        filetypes=[(\"Image Files\", \"*.png;*.jpg;*.jpeg;*.bmp;*.gif\")]\n",
    "    )\n",
    "    if file_path:\n",
    "        img = Image.open(file_path)\n",
    "        img.thumbnail((300, 300))  # Resize the image to fit in the window\n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "        image_label.config(image=img_tk)\n",
    "        image_label.image = img_tk\n",
    "        file_path_label.config(text=f\"File: {file_path}\")\n",
    "\n",
    "        # Display some information in the text box\n",
    "        output_text.delete(\"1.0\", tk.END)  # Clear previous text\n",
    "        output_text.insert(tk.END, f\"File Path: {file_path}\\n\")\n",
    "        output_text.insert(tk.END, f\"Image Size: {img.size}\\n\")\n",
    "        output_text.insert(tk.END, f\"Image Format: {img.format}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "installing:\n",
    "\n",
    "pip install transformers opencv-python matplotlib\n",
    "\n",
    "must download this https://drive.google.com/file/d/1m1sjY4ihXBU1fZXdQ-Xdj-mDltW-2Rqv/view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction:\n",
    "What's the problem and why do we care."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method:\n",
    "We are using the Segment Anything Model. We chose this because of the low barrier to entry, and it's inherent effectiveness with "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
